{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-100899e0deea9789",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Tutorial 24: Data files and I/O\n",
    "\n",
    "## PHYS 2600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e4302376dbe2ef21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to import packages and download the files used in the tutorial\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "remote_dir = \"https://raw.githubusercontent.com/wlough/CU-Phys2600-Fall2025/main/tutorials/tut24/tut24_data/\"\n",
    "local_dir = \"tut24_data\" # equivalent to \"./tut24_data\"\n",
    "filenames = [\"example_data_1.lsv\", \"example_data_tut24.csv\", \"temp_data.lsv\", \"weather_data_boulder_0918.csv\"]\n",
    "\n",
    "# Ensure local directory exists\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "for filename in filenames:\n",
    "    remote_url = remote_dir + filename\n",
    "    local_path = os.path.join(local_dir, filename)\n",
    "    # Download the file if missing\n",
    "    if not os.path.exists(local_path):\n",
    "        urllib.request.urlretrieve(remote_url, local_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7962c4e129aca38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## T24.1 - Basic file I/O \n",
    "\n",
    "Let's start with some basic file parsing.  We'll begin the same line-separated value file `example_data_1.lsv` that  I used in lecture.  First, I've given you the code I wrote in lecture to read the file and process the data into a numerical list:  __run the cell below__ to do this.\n",
    "\n",
    "(Note that I put this data file, and all the others you'll be using below, into a directory called `tut24_data`.  To access files in the directory, we use path notation with a `/` after the directory name, as you can see below.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-31b02cc91303f359",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('tut24_data/example_data_1.lsv') as data_file:\n",
    "    lines = data_file.readlines()\n",
    "\n",
    "proc_data = []\n",
    "for raw_data in lines:\n",
    "    proc_data.append(float(raw_data.strip()))\n",
    "    \n",
    "print(proc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81db3b70caa8ef3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, your job is to reverse the process!  In the cell below, write some code which will __write a new LSV file called `tut24_1A.lsv`__ containing the numbers in `proc_data`.  If you do this correctly, the file you produce should look _identical_ to the original `example_data_1.lsv` file.  (Don't forget to include the newline `\\n` characters when you're writing out!)\n",
    "\n",
    "_(Reminder: to write instead of reading, use the syntax `open(file_name, 'w')`.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-674c9c77d17ab526",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f93d57ad8c3f6cba",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Testing cell - read the new file back as LSV data, make sure it matches proc_data\n",
    "with open('tut24_1A.lsv') as data_file:\n",
    "    test_lines = data_file.readlines()\n",
    "\n",
    "test_data = []\n",
    "for raw_data in test_lines:\n",
    "    test_data.append(float(raw_data.strip()))\n",
    "    \n",
    "print(test_data)\n",
    "\n",
    "import numpy.testing as npt\n",
    "npt.assert_allclose(test_data, proc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2e3d48eaa111fc88",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part B\n",
    "\n",
    "Next, we'll deal with a couple of complications.  The file `temp_data.lsv` in the `tut24_data/` folder contains some more numbers, corresponding to a sequence of temperature measurements.  If you open the file, you'll see that the first row is a __header__: rather than a number, it is a string which describes the following data.  (This is an example of __metadata__ - data that exists to tell us about other data.)\n",
    "\n",
    "Headers are useful to have in data files - they tell us important information about the data.  But since they're not the same as the rest of the data, we have to discard them when we parse the rest of the data!\n",
    "\n",
    "In the cell below, __read the file `temp_data.lsv`__ to produce a list called __`temp_data`__.  This list should be a list of floats, like `proc_data` above - which means it should _not_ include the header.\n",
    "\n",
    "_(Hint: remember, both `.readline()` and `.readlines()` have state memory; they won't read the same line twice.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-49e5817b28994d9f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-822c3e365d0569de",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(temp_data)\n",
    "\n",
    "assert len(temp_data) == 7\n",
    "npt.assert_allclose(temp_data, [34, 35, 40, 31, 25, 36, 42])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c00234bd5d15f5ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, repeat the exercise that you did in part A: write `temp_data` out to a file in LSV format.  But write it to the __same file__, `tut24_1A.lsv`, using the \"append\" mode so that the previous data remains.  If you do this right, you should see a file containing the 15 numbers from `example_data_1.lsv` followed by the 7 numbers from `temp_data.lsv`.\n",
    "\n",
    "_(Reminder: to append, use the syntax `open(file_name, 'a')`.  If you make a mistake, you might need to re-run your code from part A to re-create the original file before you append to it here.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d62b22b5eaf47b94",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d19f0c8ebf0deee",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "## Testing cell - read the final version of tut24_1A.lsv\n",
    "with open('tut24_1A.lsv') as data_file:\n",
    "    test_lines = data_file.readlines()\n",
    "\n",
    "test_data = []\n",
    "for raw_data in test_lines:\n",
    "    test_data.append(float(raw_data.strip()))\n",
    "    \n",
    "print(test_data)\n",
    "assert len(test_data) == 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-745b3cbf5029a49c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## T24.2 - Comma-separated value files\n",
    "\n",
    "\n",
    "Line-separated value data is too simplistic; it's not used much in practice.  Instead, the most popular basic text-file format for storing data is __comma-separated values__, or \"CSV\".  CSV is a _tabular_ (two-dimensional) format, using lines to separate rows and commas to separate columns:\n",
    "\n",
    "```\n",
    "t,x,y,z\n",
    "0.0,1.3,0.2,-0.4\n",
    "0.2,2.4,0.7,-1.1\n",
    "(...)\n",
    "```\n",
    "\n",
    "When parsing a CSV file, we still need to use `.strip()` to get rid of newline characters.  But we also need to split apart our data using the commas.  To accomplish that, we can use another version useful method called `.split()`.  Here's a demonstration:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4bd88646db536a5d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "csv_line = '0.0,1.3,0.2,-0.4\\n'\n",
    "print(csv_line.split(','))\n",
    "print(csv_line.strip().split(','))  ## Strip first to get rid of the \\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fe8e69f1c3e3fdef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part A\n",
    "\n",
    "Let's get some practice with the CSV format.  I've provided a comma-separated value file called `example_data_tut24.csv`.\n",
    "\n",
    "Since a CSV file is human-readable, a good place to start is to __open the file and look at its contents.__  You should see how many rows and columns to expect.  You'll also notice that this particular file contains a __header__, once again: the very first line of the file doesn't contain data, but instead a set of strings that describe the data columns below.\n",
    "\n",
    "The cell below contains an example line of data from this CSV file, formatted as a string.  To get the numbers out as a list, you should carry out the following steps:\n",
    "\n",
    "1. Use the `.strip()` string method to get rid of the newline character `\\n`.\n",
    "2. Use the `.split()` string method to divide the string into smaller strings.\n",
    "3. Convert each string in the list to a floating-point number using the `float()` type-casting function.  (You'll need a `for` loop to run through the list.)\n",
    "\n",
    "__Implement the function `parse_line_csv` below__ to carry out these three steps, then run the cell below to run it on `sample_line` and check that you parsed it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-92bdb8a08bb8bb51",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sample_line = '1,3.31,-0.27,7.79\\n'\n",
    "\n",
    "def parse_line_csv(line):\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6a9acf2904c19bd2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parsed_line = parse_line_csv(sample_line)\n",
    "print(parsed_line)\n",
    "\n",
    "import numpy.testing as npt\n",
    "npt.assert_allclose(parsed_line, [1.0, 3.31, -0.27, 7.79])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c3977ae033786f17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part B\n",
    "\n",
    "Now you're ready to process the whole data file!  In the cell below, use the `with open(...) as ...` syntax to open the file `example_data_tut24.csv`, and then use `readline()` or `readlines()` and your function from part A to create a two-dimensional NumPy array containing the data.  __Save it to a variable called `proc_data`.__\n",
    "\n",
    "_(Hint: don't forget the header line!  Since it contains metadata and not data, you should store that to a different variable or discard it entirely.)_\n",
    "\n",
    "_(Another hint: it's easiest to make a list of lists, and then use `np.array()` to typecast at the end.  You could also allocate an array of zeroes and then fill it in, line by line, but that requires knowing the exact dimensions of the data before you start by looking at the file - not always practical!)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1054b9918bbc8be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "data_filename = 'tut24_data/example_data_tut24.csv'\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1961b4fdef4cd111",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(proc_data)\n",
    "print(proc_data.shape)\n",
    "\n",
    "import numpy.testing as npt\n",
    "npt.assert_allclose(proc_data[9], [10, -4.63, 3.13, 7.47])\n",
    "assert proc_data.shape == (12,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-edf5bd56254c036e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part C\n",
    "\n",
    "Now our data is ready to use!  Let's apply a transformation.  Say we want to convert the middle two columns (x,y) to a single distance $d = \\sqrt{x^2 + y^2}$ (discarding the final 'time' measurement column.)  That's easy enough to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-64072e9be23600bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distance_data = np.zeros((12,2))\n",
    "distance_data[:,0] = proc_data[:,0]\n",
    "distance_data[:,1] = np.sqrt(proc_data[:,1]**2 + proc_data[:,2]**2)\n",
    "\n",
    "print(distance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6e00367022b023a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we'd like to __write the transformed data out__ to a new file called `distances.csv`.  Use the `with open(..., 'w') as ...` context syntax to open `distances.csv` for writing, and then use the `.write()` file method to write lines to the file.  \n",
    "\n",
    "__Use string formatting with the `g` format code__ for both numbers, and don't forget to include the newline `\\n` at the end of every line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e565d219d9093cc5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-266bc7249fd9c8c9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "with open('distances.csv', 'r') as dist_file:\n",
    "    dlines = dist_file.readlines()\n",
    "\n",
    "print(dlines)\n",
    "assert len(dlines) == 12\n",
    "assert dlines[4] == '5,4.61525\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-653133e7666e16d4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## T24.3 - Data mining the weather (optional challenge)\n",
    "\n",
    "_(Note: I'm including a very long optional challenge this time.  If you're not currently working with real data files, or planning to do so soon, then the two parts of this tutorial above are probably good enough for you to learn the basics of file I/O.  But real data comes with a lot of new challenges, so I'm hoping this part will be a valuable exercise for some of you.)_\n",
    "\n",
    "\n",
    "Finally, let's try working with some real data!  The provided file `weather_data_boulder_0918.csv` contains [NOAA weather data](https://www.ncdc.noaa.gov/cdo-web/) for various weather stations in the vicinity of Boulder, taken over 28 days in the month of September 2018.  The columns, in order, are:\n",
    "\n",
    "* Weather station ID\n",
    "* Weather station name\n",
    "* Date of observation\n",
    "* Precipitation total (inches)\n",
    "* Average temperature (degrees F)\n",
    "* Max temperature (degrees F)\n",
    "* Min temperature (degrees F)\n",
    "\n",
    "Since this is a real dataset, we'll encounter many real-world data wrangling problems: \"cleaning\" out extraneous data we don't care about, transforming and combining data, and so on.\n",
    "\n",
    "Once again, start by __opening up the raw data file and looking through it__ to get a sense for the raw data.  One line will look something like this:\n",
    "\n",
    "\"USS0005J42S\",\"NIWOT, CO US\",\"2018-09-14\",\"0.00\",\"57\",\"72\",\"41\"\n",
    "\n",
    "In fact, this line with all data filled in is _rare_: most of the stations reported seem to only measure precipitation, so their temperature columns are missing entirely.  Of the stations reporting temperatures, most only record max/min and not the average.  Real data is often messy!\n",
    "\n",
    "\n",
    "### Part A\n",
    "\n",
    "Notice that this file is especially challenging to parse: this is a variation on CSV where the data are contained in double quotes `\"\"` and _then_ separated by commas.  This is done so that commas can be used _inside_ the dataset, as in the station name above.\n",
    "\n",
    "As a warm-up, I've included a single line of the data file as a string below.  __Extract the precipitation, max temperature, and min temperature__ from this string as a 3-entry NumPy array.\n",
    "\n",
    "\n",
    "_(Hint: if you just pretend this is a regular CSV file and split on the commas, you'll end up breaking apart the station name field.  But if you only want the precipitation and temperature data, you can just ignore the name - but keep track of which column ends up where in the list after using `split`...)_\n",
    "\n",
    "_(Another hint: the double quotes `\"` will only get in your way here!  You can remove all the instances of a character from a string by using the `.replace()` method.  For example, `\"hello world\".replace('l', '')` will give you the string `'heo word'`.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0adf1e4a5b5a10de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wline = '\"USS0005J42S\",\"NIWOT, CO US\",\"2018-09-14\",\"0.00\",\"57\",\"72\",\"41\"\\n'\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5bccb3f17c01437a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part B\n",
    "\n",
    "Now parse the whole data file, and __create a 2-D NumPy array containing the precipitation, max temperature, and min temperature__ for __only a single Boulder station, ID `USW00094075`.__  There are two ways you can do this:\n",
    "\n",
    "1. Pretend this is a regular CSV file, and parse it by splitting on the commas as you did for the single line in part A.\n",
    "2. Use the `csv` module [see the documentation here](https://docs.python.org/3/library/csv.html), and use a `csv.reader` to parse the dataset.  The `csv` module can recognize variations of CSV like this one and will deal with the quotes properly if you set the `quotechar` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2616ec7725948339",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "weather_filename = 'tut24_data/weather_data_boulder_0918.csv'\n",
    "boulder_data = []\n",
    "\n",
    "#\n",
    "\n",
    "print(boulder_data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b0603f050d01101e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part C\n",
    "\n",
    "Now extract the following quantities from your cleaned array of data in the cell below:\n",
    "\n",
    "* Total precipitation;\n",
    "* The lowest minimum temperature and highest maximum temperature;\n",
    "* The average temperatures (obtained by averaging min/max temperature) on every Tuesday.\n",
    "\n",
    "_(Hint: for the last one, use `np.mean()` and slicing to produce a 1d array containing the average temperature, then one more slice to cut the list down to the four Tuesdays only.  The data runs from 9/2 to 9/29, so the first day is a Sunday and the last is a Saturday.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-23cc3adf1fc2b283",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52ada97250412743",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part D\n",
    "\n",
    "Can you go back and report the lowest minimum and highest maximum temperature across _all weather stations_ in the file?  (This is tricky because many of the stations don't report any temperatures at all!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a52e8c19bfe55db3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
